Base: # The `Base` is shared by different expid settings
    model_root: './checkpoints/'
    num_workers: 3
    verbose: 1
    patience: 2
    pickle_feature_encoder: True
    use_hdf5: True
    save_best_only: True
    every_x_epochs: 1
    debug: False
    partition_block_size: -1
    dataset_id: taobao_tiny
    gpu: 0


DeepFM_base:
    model: DeepFM
    loss: 'binary_crossentropy'
    metrics: ['logloss', 'AUC']
    task: binary_classification
    optimizer: adam
    hidden_units: [300, 300, 300]
    hidden_activations: relu
    net_regularizer: 0
    embedding_regularizer: 0
    learning_rate: 1.e-3
    batch_norm: False
    net_dropout: 0
    batch_size: 10000
    embedding_dim: 16
    epochs: 100
    shuffle: True
    seed: 2019
    monitor: {'AUC': 1, 'logloss': -1}
    monitor_mode: 'max'


DeepFM_fft:
    model: DeepFM_fft
    loss: 'binary_crossentropy'
    metrics: ['logloss', 'AUC']
    task: binary_classification
    optimizer: adam
    hidden_units: [300, 300, 300]
    hidden_activations: relu
    net_regularizer: 0
    embedding_regularizer: 0
    learning_rate: 1.e-3
    batch_norm: False
    net_dropout: 0
    batch_size: 10000
    embedding_dim: 16
    epochs: 100
    shuffle: True
    seed: 2019
    monitor: {'AUC': 1, 'logloss': -1}
    monitor_mode: 'max'
    alpha_fft: 1


AutoInt_base:
    model: AutoInt
    loss: 'binary_crossentropy'
    metrics: ['logloss', 'AUC']
    task: binary_classification
    optimizer: adam
    learning_rate: 1.e-3
    embedding_regularizer: 0
    net_regularizer: 0
    batch_size: 10000
    embedding_dim: 16
    dnn_hidden_units: [400, 400]
    dnn_activations: relu
    net_dropout: 0
    num_heads: 2
    attention_layers: 3
    attention_dim: 40
    use_residual: True
    batch_norm: False
    layer_norm: False
    use_scale: False
    use_wide: False
    epochs: 100
    shuffle: True
    seed: 2019
    monitor: {'AUC': 1, 'logloss': -1}
    monitor_mode: 'max'

AutoInt_fft:
    model: AutoInt_fft
    loss: 'binary_crossentropy'
    metrics: ['logloss', 'AUC']
    task: binary_classification
    optimizer: adam
    learning_rate: 1.e-3
    embedding_regularizer: 0
    net_regularizer: 0
    batch_size: 10000
    embedding_dim: 16
    dnn_hidden_units: [400, 400]
    dnn_activations: relu
    net_dropout: 0
    num_heads: 1
    attention_layers: 3
    attention_dim: 40
    use_residual: True
    batch_norm: False
    layer_norm: False
    use_scale: False
    use_wide: False
    epochs: 100
    shuffle: True
    seed: 2019
    monitor: {'AUC': 1, 'logloss': -1}
    monitor_mode: 'max'
    alpha_fft: 1


DCN_base:
    model: DCN
    loss: 'binary_crossentropy'
    metrics: ['logloss', 'AUC']
    task: binary_classification
    optimizer: adam
    learning_rate: 1.0e-3
    embedding_regularizer: 0
    net_regularizer: 0
    batch_size: 10000
    embedding_dim: 16
    dnn_hidden_units: [500, 500, 500]
    dnn_activations: relu
    crossing_layers: 3
    net_dropout: 0
    batch_norm: False
    epochs: 100
    shuffle: True
    seed: 2019
    monitor: {'AUC': 1, 'logloss': -1}
    monitor_mode: 'max'


DCN_fft:
    model: DCN_fft
    loss: 'binary_crossentropy'
    metrics: ['logloss', 'AUC']
    task: binary_classification
    optimizer: adam
    learning_rate: 1.0e-3
    embedding_regularizer: 0
    net_regularizer: 0
    batch_size: 10000
    embedding_dim: 16
    dnn_hidden_units: [500, 500, 500]
    dnn_activations: relu
    crossing_layers: 3
    net_dropout: 0
    batch_norm: False
    epochs: 100
    shuffle: True
    seed: 2019
    monitor: {'AUC': 1, 'logloss': -1}
    monitor_mode: 'max'
